## Optimizers
Focus on papers and related resources that propose deep learning optimization algorithms.

## Papers
* (***Adam***)  **Adam: A Method for Stochastic Optimization**, *Diederik P. Kingma, Jimmy Ba*, ICLR 2015  [[PDF]](https://arxiv.org/pdf/1412.6980v9.pdf)  [[Official PyTorch Implementation]](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam)  #  [[Notes]](https://www.hjhgjghhg.com/index.php/archives/151/)
* (***AMSGrad***) **On the Convergence of Adam and Beyond**, *Sashank J. Reddi, Satyen Kale, Sanjiv Kumar*, ICLR 2018 (Best Paper)  [[ICLR PDF]](https://arxiv.org/)  [[Official PyTorch Implementation]](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam)  #  [[Notes]](https://www.hjhgjghhg.com/index.php/archives/158/)
* (***SWATS***) **Improving Generalization Performance by Switching from Adam to SGD**, *Nitish Shirish Keskar, Richard Socher*，arXiv 2017  [[PDF]](https://arxiv.org/pdf/1712.07628.pdf)  [[PyTorch Implementation]](https://github.com/Mrpatekful/swats)  #  [[Notes]](https://www.hjhgjghhg.com/index.php/archives/166/)
* (***SignSGD***) **SignSGD: Compressed Optimisation for Non-Convex Problems**，*Jeremy Bernstein, Yu-Xiang Wang, Kamyar Azizzadenesheli, Anima Anandkumar*，ICML 2018  [[ICML PDF]](http://proceedings.mlr.press/v80/bernstein18a/bernstein18a.pdf)  [[Newest Version PDF]](https://arxiv.org/pdf/1802.04434.pdf)  [[Official PyTorch Implementation]](https://github.com/jxbz/signSGD)  #  [[Notes]](https://www.hjhgjghhg.com/index.php/archives/177/)
* (***AdaBound***) **Adaptive Gradient Methods with Dynamic Bound of Learning Rate**, *Liangchen Luo, Yuanhao Xiong, Yan Liu, Xu Sun*, ICLR 2019  [[ICLR PDF]](https://openreview.net/pdf?id=Bkg3g2R9FX)  [[Official PyTorch Implementation]](https://github.com/Luolc/AdaBound)  #  [[Notes]](https://www.hjhgjghhg.com/index.php/archives/166/)
* (***AdamW***) **Decoupled Weight Decay Regularization**，*Ilya Loshchilov, Frank Hutter*，ICLR 2019  [[ICLR PDF]](https://openreview.net/pdf?id=Bkg6RiCqY7)  [[Newest Version PDF]](https://arxiv.org/pdf/1711.05101.pdf)  [[Official PyTorch Implementation]](https://github.com/loshchil/AdamW-and-SGDW)  #  [[Notes]](https://www.hjhgjghhg.com/index.php/archives/172/)
* (***SignAdam***) **signADAM++: Learning Confidences for Deep Neural Networks**，*Dong Wang, Yicheng Liu, Wenwo Tang, Fanhua Shang, Hongying Liu, Qigong Sun, Licheng Jiao*，ICDMW 2019  [[PDF]](https://arxiv.org/pdf/1907.09008.pdf)  [[Official PyTorch Implementation]](https://github.com/DongWanginxdu/signADAM-Learn-by-Confidence)