## Analysis
Focus on papers and related resources that provide theoretical or empirical analysis for deep learning optimization algorithms.

## Convergence Analysis
* **On the convergence of a class of Adam-type algorithms for non-convex optimization**，*Xiangyi Chen, Sijia Liu, Ruoyu Sun, Mingyi Hong*，ICLR 2019，2018
* **On the convergence proof of AMSGrad and a new version**，*Tran Thi Phuong,  Le Trieu Phong*，IEEE Access，2019
* **A Simple Convergence Proof of Adam and Adagrad**，*Alexandre Défossez, Léon Bottou, Francis Bach, Nicolas Usunier*，arXiv preprint arXiv:2003.02395，2020
* **Towards practical Adam: Non-convexity, convergence theory, and mini-batch acceleration**，*Congliang Chen, Li Shen, Fangyu Zou, Wei Liu*，JMLR，2022
